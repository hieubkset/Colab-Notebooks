{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-classification-with-hub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMgZd12kd9ytlXBb5RSdgeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieubkset/Colab-Notebooks/blob/master/text-classification-with-hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gN9lOdASB3q",
        "colab_type": "text"
      },
      "source": [
        "# **Phân loại văn bản**\n",
        "\n",
        "Một ví dụ về bài toán phân loại văn bản trên tập dữ liệu [IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb).\n",
        "\n",
        "Mục tiêu:\n",
        "\n",
        "+ Có cái nhìn tổng quan về [TensorFlow Hub](https://www.tensorflow.org/hub) và [TensorFlow datasets](https://www.tensorflow.org/datasets).\n",
        "+ Hiểu cơ bản việc sử dụng transfer learning để chuyển đổi từ text sang embedding vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gexGGGrHa3N1",
        "colab_type": "text"
      },
      "source": [
        "## **Giới thiệu IMDB dataset**\n",
        "\n",
        "[IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) bao gồm review (đánh giá) của 50,000 bộ phim từ [Internet Movie Database](https://www.imdb.com/). Trong đó, 25,000 review cho training và 25,000 reivew còn lại cho testing. Mỗi review là một câu bình luận về bộ phim và được gán một trong 2 nhãn: positive (tích cực) hoặc negative (tiêu cực). Số lượng nhãn positive và negative là chia đều trong cả tập training và testing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IppAoB2abF7J",
        "colab_type": "text"
      },
      "source": [
        "## **Chương trình**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTu0tw--bNWO",
        "colab_type": "text"
      },
      "source": [
        "### **1. Khai báo các thư viện**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcDm9C1DFxDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install tensorflow-hub\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a79vkdU0boWb",
        "colab_type": "text"
      },
      "source": [
        "### **2. Chuẩn bị data**\n",
        "\n",
        "Ở các bài trước, chúng ta đã học cách load data với **tf.keras.datasets**. Ở bài này, chúng ta sẽ làm quen với một kho data khác to hơn là [Tensorflow Datasets](https://www.tensorflow.org/datasets). \n",
        "\n",
        "**Tensorflow Datasets** cung cấp khoảng 29 bộ dataset như: MNIST, Street View House Numbers, the 1 Billion Word Language Model Benchmark, v.v... và được cập nhật thường xuyên.\n",
        "\n",
        "Tất cả các dataset trong **Tensorflow Datasets** là một thể hiển của  [tf.data.Datasets](https://www.tensorflow.org/api_docs/python/tf/data/Dataset). Hiểu một cách đơn giản là các dataset này đã chuẩn hóa nên rất dễ sử dụng và cho hiệu năng cao.\n",
        "\n",
        "Dưới đây là một ví dụ load **IMDB dataset** với **Tensorflow Datasets** (tfds):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5bCpCptGFWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name='imdb_reviews',\n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IJgePjmevye",
        "colab_type": "text"
      },
      "source": [
        "** Explore data**\n",
        "\n",
        "Chúng ta sẽ xem định dạng của dữ liệu trước khi tiến hành build model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSB_npfGGqSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples_batch, train_lables_batch = next(iter(train_data.batch(10)))\n",
        "train_examples_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2yGpag5HhKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_lables_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6BoYmfDi2Yc",
        "colab_type": "text"
      },
      "source": [
        "Label gồm 2 giá trị: 1 tương ứng với positive và 0 tương ứng với negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSjbxfwgjGpp",
        "colab_type": "text"
      },
      "source": [
        "### **3. Build model**\n",
        "\n",
        "Để xử lý dữ liệu đầu vào là các review dưới dạng text có chiều dài bất kỳ, chúng ta sẽ sử dụng một pre-trained text embedding model để chuyển đầu vào từ text sang embedding vector (có chiều dài cố định).\n",
        "\n",
        "Cụ thể, chúng ta sử dụng [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1) từ [TensorFlow Hub](https://www.tensorflow.org/hub).\n",
        "\n",
        "**TensorFlow Hub** là nơi cung cấp các pre-trained model - các model được train trên các tập dataset (thường nhiều data). Chúng ta có thể dùng toàn bộ hoặc một phần của pre-trained model để tiến hành training trên dataset của chúng ta (thường ít data). Quá trình này gọi là transfer learning.\n",
        "\n",
        "**TensorFlow Hub** hỗ trợ việc sử dụng pre-trained model như một keras layer. Ví dụ: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJbTIk4cTMdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
        "hub_layer(train_examples_batch[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et9-zCT7lo9l",
        "colab_type": "text"
      },
      "source": [
        "*Chúng ta có thể thấy thấy dữ liệu được chuyển từ text sang embedding vector có 20 dim (chiều).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5uqaTLfl_pG",
        "colab_type": "text"
      },
      "source": [
        "**Định nghĩ model:**\n",
        "+ pre-trained model được sử dụng như input layer chuyển đổi đầu vào từ text sang embedding vector có số chiều cố định là 20.\n",
        "+ Dense layer với 16 hidden unit\n",
        "+ Output layer với 1 unit. Vì bài toán chỉ có 2 class nên ta chỉ cần một output cho biết xác suất ứng với possitive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO8x-gnQW_H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRMcyEsnY8T",
        "colab_type": "text"
      },
      "source": [
        "#### **4. Khai báo Optimizer và Loss function**\n",
        "Chúng ta vẫn sử dụng Adam Optimizer :) Tuy nhiên, vì chỉ có 2 class nên ta dùng **BinaryCrossentropy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FwJ-m9iXUS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss= tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7kE0ZxhoB7B",
        "colab_type": "text"
      },
      "source": [
        "### **5. Tiến hành training**\n",
        "\n",
        "Train model trong 20 epoch với batch size là 512. Trong quá trình training, các thông số như loss và accuracy trên tập validation sẽ được lưu lại (*chúng ta sẽ tìm hiểu cách hiển thị các thông số này ở bài sau*).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5iNVPEWZQMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgQqHIJjpBOC",
        "colab_type": "text"
      },
      "source": [
        "**6. Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFtNISErZtr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "    print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnMfzUUppLUJ",
        "colab_type": "text"
      },
      "source": [
        "Với 20 epoch, model cho accuracy trên tập test khoảng 87%. Với cách tiếp cận nâng cao hơn, accuracy có thể lên tới 95%."
      ]
    }
  ]
}